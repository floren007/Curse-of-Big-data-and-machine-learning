{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "496631ea",
   "metadata": {},
   "source": [
    "# Módulo 1: Análisis de datos en el ecosistema Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a14cd3f",
   "metadata": {},
   "source": [
    "### Sesión (4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acd93e7",
   "metadata": {},
   "source": [
    "**26/09/2022**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461d3392",
   "metadata": {},
   "source": [
    "# Exploración y tratamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec781ba",
   "metadata": {},
   "source": [
    "Breve resumen de herramientas principales de tratamiento de datos en Python:\n",
    "\n",
    "#### **Numpy:**\n",
    "* Paquete específico muy útil para trabajar con **arrays y matrices**\n",
    "* Podemos crear arrays desde cero (útil cuando queremos arrays **multidimensionales**)\n",
    "\n",
    "\n",
    "#### **Matplotlib:**\n",
    "* Paquete para pintar gráficos a partir de datos contenidos en listas o arrays.\n",
    "* Se usa la extensión matemática numpy\n",
    "\n",
    "#### **Pandas:**\n",
    "* Paquete que sirve para trabajar con datos\n",
    "* La librería Pandas dispone de tres estructuras principales:\n",
    "    * __DataFrames__\n",
    "    * __Series__\n",
    "    * __Index__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d19dc4b",
   "metadata": {},
   "source": [
    "## Gráficos\n",
    "Existen varias librerías y paquetes para pintar gráficos en python. Uno de los más populares es el **[matplotlip](https://matplotlib.org/stable/)**, que tiene una sintaxis que proviene de **Matlab**.\n",
    "\n",
    "Para usarlo en Jupyter vamos a utilizar un [comando \"mágico\"](http://ipython.readthedocs.io/en/stable/interactive/magics.html). Jupyter permite hacer cosas que no son código Python, el que vamos a usar aquí configura Jupyter para que la salida de los gráficos de matplotlib se muestre en el propio cuaderno (en vez de guardarse en un archivo separado)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f103591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta celda suele estar en todos los notebooks que hagan tratamiento de datos\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4a274f",
   "metadata": {},
   "source": [
    "Pintamos un gráfico sencillo a partir de un conjunto de puntos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723d5f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por defecto se pinta un \"line plot\"\n",
    "plt.plot([10,20,30,40], [200,300,400,100])\n",
    "plt.xlabel('Tiempo [min]')\n",
    "plt.ylabel('Potencia [kW]')\n",
    "plt.title('Motor 1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22a7857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos indicar el tipo gráfico indicando muchas opciones\n",
    "plt.plot([10,20,30,40], [200,300,400,100], color='blue', marker='o', linestyle='dashed', linewidth=2, markersize=12)\n",
    "plt.xlabel('Tiempo [min]')\n",
    "plt.ylabel('Potencia [kW]')\n",
    "plt.title('Motor 1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47e1b21",
   "metadata": {},
   "source": [
    "Se pueden modificar los parámetros de estilado por defecto de **matplotlib** mediante [rcParams (runtime configuration Parameters)](https://matplotlib.org/3.5.0/api/matplotlib_configuration_api.html#matplotlib.rcParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ff8b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificar los parámetros del gráfico\n",
    "plt.rcParams['figure.figsize'] = 12, 6 # el primer dígito es el ancho y el segundo el alto\n",
    "plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "plt.rcParams[\"font.size\"] = 10\n",
    "plt.rcParams[\"axes.labelweight\"] = \"bold\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea921ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot([10,20,30,40], [200,300,400,100], color='blue', marker='o', linestyle='dashed', linewidth=2, markersize=12)\n",
    "\n",
    "plt.xlabel('Tiempo [min]', fontsize='large', fontweight='bold')\n",
    "plt.ylabel('Potencia [kW]', fontsize='large', fontweight='bold')\n",
    "plt.title('Motor 1', fontsize=20, fontweight='bold')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36194694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para volver a los valores y los ajustes por defecto\n",
    "plt.rcdefaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91313a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# El mismo gráfico esta vez con parámetros y ajustes por defecto!!\n",
    "plt.plot([10,20,30,40], [200,300,400,100], color='blue', marker='o', linestyle='dashed', linewidth=2, markersize=12)\n",
    "\n",
    "plt.xlabel('Tiempo [min]', fontsize='large', fontweight='bold')\n",
    "plt.ylabel('Potencia [kW]', fontsize='large', fontweight='bold')\n",
    "plt.title('Motor 1', fontsize=20, fontweight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001197e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un ejemplo más avanzado\n",
    "# Desde la sección numpy sabemos que la función np.linspace() nos permite crear un array con valores equidistantes\n",
    "X = np.linspace(-np.pi, np.pi, 180)\n",
    "Coseno = np.cos(X)\n",
    "Seno = np.sin(X)\n",
    "\n",
    "# Usamos la opción scatterplot que pinta solamente los puntos en vez de dibujar lineas\n",
    "plt.scatter(X, Coseno, s=10)\n",
    "plt.scatter(X, Seno, s=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711a2ffc",
   "metadata": {},
   "source": [
    "### **`Ejercicio 4.1`**\n",
    "\n",
    "Crea un gráfico con puntos rojos que visualice el valor de cada número elevado al cubo para 100 números repartidos de forma equidistantes entre 0 y 10 (no inclusive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac27d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solución\n",
    "# Ejercicio 4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcf2e70",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6323e25d",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6e7249",
   "metadata": {},
   "source": [
    "* **Pandas** es un paquete basado en **numpy** y otros que sirve para trabajar con datos.\n",
    " \n",
    "* Pandas incorpora muchas cosas que facilitan el análisis de datos:\n",
    "    * Arrays etiquetados (**labeled arrays**)\n",
    "    * Introducir datos heterogéneos en una tabla (similar a los **DataFrames** de R)\n",
    "    * Los valores perdidos (**missing values**) se tratan mejor\n",
    "    * **Funciones** útiles estadísticas, para pintar gráficos, calcular nuevas variables, etc.\n",
    "    * más **tipos** de datos (**Categorical** para variables categóricas, **Datetime** para fechas)\n",
    "\n",
    "\n",
    "* Para poder empezar a usar pandas necesitamos tener instalado el numpy, después podemos importar pandas mediante el comando `import` que por convenio suele importarse bajo el acrónimo de `pd`\n",
    "\n",
    "* La librería Pandas dispone de tres estructuras principales:  \n",
    "    * **Series**\n",
    "    * **DataFrames**\n",
    "    * **Index**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77c51f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcfb7bf",
   "metadata": {},
   "source": [
    "## Pandas Series\n",
    "\n",
    "* Un pandas series se trata de **un array unidimensional indexada** o mejor dicho **etiquetada**. \n",
    "\n",
    "* Este tipo de datos pueden ser creados a partir de un array unidimensional o de una lista de la siguiente forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4166236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos creamos un objeto tipo serie\n",
    "data = pd.Series([10, 20, 15, 10, 17],index = ['a', 'b', 'c', 'd','e'])\n",
    "\n",
    "# Mostramos el resultado\n",
    "print(data)\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d99fb71",
   "metadata": {},
   "source": [
    "Una serie dispone tanto de una **secuencia de valores** (los datos de nuestra lista/array), además de una **secuencia de índices**.\n",
    "\n",
    "* Podemos acceder tanto a los valores como a los índices mediante los atributos: `.values` e `.index` respectivamente.\n",
    "* Podemos ver las características de una serie mediante `.size ` (devuelve el número de elementos de la serie) y `.dtype` (devuelve el tipo de datos de los elementos de la serie).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46002da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accedemos a los valores de nuestra serie\n",
    "print(data.values)\n",
    "\n",
    "# Vemos su tipo \n",
    "print(type(data.values))\n",
    "\n",
    "# Accedemos a los índices\n",
    "print(data.index) \n",
    "\n",
    "# Consultamos el tipo de datos para los índices\n",
    "print(type(data.index)) \n",
    "\n",
    "# Consultamos el número de elementos de la serie\n",
    "print(data.size) \n",
    "\n",
    "# Consultamos el tipo de datos de los elementos de la serie\n",
    "print(data.dtype) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9f777b",
   "metadata": {},
   "source": [
    "### Funciones (métodos) para  Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7718f147",
   "metadata": {},
   "source": [
    "Algunos **métodos para Series**:\n",
    "* **data.value_counts():** Devuelve un objeto que contiene en orden de frecuencia, los distintos valores existentes en la serie junto con el número de apariciones de cada uno.  \n",
    "* **data.unique():** Devuelve un array con los valores únicos de la serie.  \n",
    "* **data.sort_values():** Devuelve la serie con valores ordenados. Por defecto en orden ascendiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc101074",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a034f84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5939dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fd498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b601a2",
   "metadata": {},
   "source": [
    "Podemos acceder a los datos concretos a través de sus índices, de igual forma que hacíamos en un numpy array, haciendo uso de los **corchetes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7465a190",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"La serie =\")\n",
    "print(data)\n",
    "\n",
    "# Accedemos al primer valor de nuestra serie (como si fuera un array)\n",
    "print(\"\\n Primer elemento =\", data[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c040bc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accedemos al segundo y al tercer elemento de nuestra serie\n",
    "data[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9daafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accedemos al elemento con índice \"b\"  de nuestra serie (como si fuera un diccionario)\n",
    "data['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d031f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accedemos a los elementos con índice \"a\",\"b\",\"c\"  de nuestra serie\n",
    "data['a':'c']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15eb0cd",
   "metadata": {},
   "source": [
    "Al igual que otros objetos mutables que hemos visto anteriormente, las series en pandas también se pueden modificar cuando se referencian por el indexado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb8e6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificamos el primer elemento referenciando su posición\n",
    "data[0] = 88\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d9976a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificamos el último elemento referenciando su índice\n",
    "data['e'] = 99\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5794c791",
   "metadata": {},
   "source": [
    "* Podríamos pensar que un objeto pandas series se trata de una especialización de un diccionario. \n",
    "* Un diccionario se trata de una estructura que asigna un conjunto de claves arbitrarias a un conjunto de valores arbitrarios, mientras que una **Serie** asigna un conjunto de **claves tipadas** a un conjunto de **valores tipados**. \n",
    "* Esta tipificación es importante: de igual forma que el código compilado que corre detrás de un Numpy array la hace más eficiente que una lista Python para ciertas operaciones, el tipado de los datos de una Serie hace que esta sea mucho más eficiente que un diccionario para ciertas operaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937cebb5",
   "metadata": {},
   "source": [
    "Podemos crear series a partir de diccionarios y diccionarios a partir de series.\n",
    "Por defecto las series son ordenadas por clave en sentido ascendente.  \n",
    "Cojemos el ejemplo de los ganadores de [Champions League:](https://es.uefa.com/uefachampionsleague/history/rankings/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7617ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos creamos una serie a partir de un diccionario\n",
    "champions_dict = {'Real_Madrid': 14, 'Milan': 7, 'Liverpool': 6, 'Bayern_Munich': 6, 'Barcelona': 5}\n",
    "\n",
    "# Mostramos el diccionario\n",
    "print(champions_dict)\n",
    "type(champions_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3e2a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos creamos nuestro pandas series a partir del diccionario\n",
    "champions_series = pd.Series(champions_dict)\n",
    "\n",
    "#Mostramos el resultado\n",
    "print(champions_series)\n",
    "type(champions_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3fcb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Las claves del diccionario original son los índices o las etiquetas de la serie\n",
    "champions_series.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7519cb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consultamos la estadística de los dos primeros equipos\n",
    "champions_series[0:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b0ab03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consultamos por el índice/clave asociado\n",
    "champions_series['Barcelona']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590e2967",
   "metadata": {},
   "source": [
    "## Dataframe\n",
    "\n",
    "* Si una serie es una analogía de un array unidimensional con índices etiquetados, un **DataFrame** es análogo a **un array bidimensional con flexibilidad de indexación** tanto para las <ins>filas</ins> como para las <ins>columnas</ins>.  \n",
    "* Podemos pensar en un **DataFrame** como objetos de tipo serie alineados. Aquí la palabra alineado quiere decir que comparten el mismo índice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489dd253",
   "metadata": {},
   "source": [
    "Los objetos Pandas DataFrame se pueden construir de diversas formas, a continuación veremos algunas de estas.\n",
    "* **A partir de una Serie:**\n",
    "Como ya hemos indicado un DataFrame es una colección de objetos tipo Serie, por lo que a partir de una sola Serie podemos crearnos un objeto de tipo DataFrame.\n",
    "* **A partir de datos guardados en formato tabular:**\n",
    "Se pueden crear DataFrames por ejemplo a partir de un archivo *csv* o *Excel*.\n",
    "* **A partir de un diccionario:**\n",
    "Cualquier diccionario o lista de diccionarios puede ser transformada a un objeto de tipo DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536862d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un conjunto de pandas series con índices iguales\n",
    "serie_temp = pd.Series({'a': 150, 'b': 100, 'c': 110})\n",
    "serie_func = pd.Series({'a': True, 'b': False, 'c': False})\n",
    "serie_pot = pd.Series({'a': 160, 'b': 180, 'c': 240})\n",
    "\n",
    "# Crear un diccionario etiquetando cada serie\n",
    "dicc_series = {'Temperatura': serie_temp,\n",
    "                'Funcionalidad': serie_func,\n",
    "                'Potencia': serie_pot}\n",
    "\n",
    "# Crear un DataFrame con el conjunto de las series etiquetadas\n",
    "df_1 = pd.DataFrame(dicc_series)\n",
    "print(type(df_1))\n",
    "df_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf9077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un DataFrame a partir de un diccionario que directamente contiene los valores de tres variables.\n",
    "# El \"index\" define la secuencia de las variables e indica que todas tienen los mismos índices (si no lo ponemos se crea uno por defecto con números).\n",
    "\n",
    "dicc = {'Temperatura': [150, 100, 110, 95, 85],\n",
    "        'Funcionalidad': [True, False, False, True, False],\n",
    "        'Potencia': [160, 180, 240, 160, 185]}\n",
    "\n",
    "df = pd.DataFrame(dicc, index=['a', 'b', 'c', 'd', 'e'])\n",
    "print(type(df))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb9f612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos los índices\n",
    "print(df.index)\n",
    "\n",
    "# Obtenemos y mostramos las etiquetas (los nombres de las columnas)\n",
    "columns = df.columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a056c55e",
   "metadata": {},
   "source": [
    "## Pandas Index\n",
    "Ya hemos visto que los objetos tipo Serie y tipo DataFrame contienen **índices** que nos permiten referenciar y modificar sus datos. Este objeto de tipo **index** se trata de una estructura muy interesante que además de ayudarnos a seleccionar los datos, también sirven para hacer operaciones entre varios dataframes.\n",
    "\n",
    "Aquí simplemente accedemos a estos datos de la siguiente forma y consultamos el tipo de dato que tienen asignado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec60fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830c7bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4289062",
   "metadata": {},
   "source": [
    "Este es un índice muy basico, pero los hay de más tipos como:\n",
    "- `MultiIndex` para índices multidimensionales (jerárquicos)\n",
    "- `DatetimeIndex` para usar fechas\n",
    "- `Float64Index` para floats\n",
    "- `CategoricalIndex` para categorías\n",
    "- `RangeIndex ` para rangos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bcb515",
   "metadata": {},
   "source": [
    "Aunque los objetos de tipo `Index` se tratan de objetos **inmutables** y una vez creados no podemos modificar su contenido, podemos aplicarles la indexación estándar de Python y además disponen de muchos de los atributos de los arrays de numpy.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba63ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtemos el primer valor de nuestro objeto index\n",
    "ind = df.index\n",
    "ind[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d140f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eso sí, son inmodificables\n",
    "ind[0] = 'aaa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87317ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos el número de elementos, tamaño, dimensión y el tipo de dato que contiene nuestro objeto de tipo index\n",
    "print(\"Los índices = \",ind)\n",
    "print(\"Número de elementos = \", ind.size)\n",
    "print(\"Tamaño = \", ind.shape)\n",
    "print(\"Dimensiones = \",ind.ndim)\n",
    "print(\"Tipo = \", ind.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00188db",
   "metadata": {},
   "source": [
    "### **`Ejercicio 4.2`**\n",
    "\n",
    "**`4.2.1`** Define una función genérica usando el método `lambda` para convertir un array a una pandas series con valores enteros.    \n",
    "**`4.2.2`** Aplica la función definida en el paso anterior sobre estos datos: `[10, True, 8.00, False, 8, 10]`  \n",
    "**`4.2.3`** Consulta la siguiente información respecto a la serie creada en el paso anterior:\n",
    "- valores de la serie\n",
    "- índices de la serie\n",
    "- tipo de datos que contiene la serie\n",
    "- número de bits que ocupa en la memoria la serie  \n",
    "  \n",
    "**`4.2.4`** Genera un gráfico básico de la serie.  \n",
    "**`4.2.5`** Saca todas las estadísticas básicas de la serie.  \n",
    "**`4.2.6`** Consigue una serie con la frecuencia de los valores de la serie.  \n",
    "**`4.2.7`** Saca todas los valores únicos de la serie.  \n",
    "**`4.2.8`** Reordena la serie con los valores en orden descendiente y con los índices reseteados.  \n",
    "**`4.2.9`** Genera un DataFrame con una columna que se llame `'ej_42'`a partir de la serie.ndiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff004fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solución\n",
    "# Ejercicio 4.2.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de24d446",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solución\n",
    "# Ejercicio 4.2.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a817286",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solución\n",
    "# Ejercicio 4.2.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677b4956",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solución\n",
    "# Ejercicio 4.2.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5c4ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solución\n",
    "# Ejercicio 4.2.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bed0fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solución\n",
    "# Ejercicio 4.2.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa64015",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solución\n",
    "# Ejercicio 4.2.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d063c4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solución\n",
    "# Ejercicio 4.2.7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9ce384",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solución\n",
    "# Ejercicio 4.2.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37369f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solución\n",
    "# Ejercicio 4.2.9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df17db6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ace5cd1",
   "metadata": {},
   "source": [
    "## DataFrame Slicing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f78f5ea",
   "metadata": {},
   "source": [
    "Para los DaraFrames existen diferentes maneras de seleccionar y filtrar los datos: \n",
    "1. Filtrar usando `[]` para seleccionar columnas por sus nombres o un rango de filas.\n",
    "2. Filtrar usando `.loc[etiquetas_filas, etiquetas_columna]` para seleccionar según etiquetas.\n",
    "3. Filtrar usando `.iloc[posiciones_filas, posiciones_columnas]` para seleccionar según posición.\n",
    "4. Filtrar por <ins>indexado booleano</ins> para seleccionar simplemente los datos que cumplan las condiciones declaradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ac9aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consultamos de nuevo el contenido y el tipo de nuestro DataFrame\n",
    "print(type(df))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a559c3e7",
   "metadata": {},
   "source": [
    "#### 1. Ejemplos con **`[]`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc8041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar una sola columna devuelve una Serie\n",
    "print(df['Temperatura'])\n",
    "\n",
    "type(df['Temperatura'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec84656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se puede seleccionar una lista de columnas (la primera y la última por ejemplo)\n",
    "columnas = ['Temperatura', 'Potencia']\n",
    "\n",
    "# En este caso el resultado es un DataFrame filtrado (por contener la unión de varias series)\n",
    "print(type(df[columnas]))\n",
    "\n",
    "df[columnas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22cfd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar un rango de filas (no se puede seleccionar una fila concreta usando solamente[])\n",
    "df['b':'d']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34529e21",
   "metadata": {},
   "source": [
    "#### 2. Ejemplos con **`.loc[]`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37b5438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar una sola fila devuelve una Serie\n",
    "print(type(df.loc['c']))\n",
    "\n",
    "df.loc['c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0942b84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se puede seleccionar una lista de filas (la primera y la penúltima por ejemplo)\n",
    "filas = ['a', 'd']\n",
    "\n",
    "# En este caso el resultado es un DataFrame filtrado (por contener la unión de varias series)\n",
    "print(type(df.loc[filas]))\n",
    "\n",
    "df.loc[filas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fd4277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se puede llegar a seleccionar un elemento concreto usando .loc[] y el nombre/etiqueta de la fila y la columna correspondiente\n",
    "# Escogemos el último elemento de la tabla\n",
    "df.loc['e', 'Potencia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8170db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filas \"c\" y \"d\", columnas \"Temperatura\" y \"Potencia\"\n",
    "df.loc[['c', 'd'], ['Temperatura', 'Potencia']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a244a90a",
   "metadata": {},
   "source": [
    "#### 3. Ejemplos con **`.iloc[]`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4934f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando .iloc[] Podemos usar el indexado habitual de numpy como si nuestro DataFrame fuera un array bidimensional\n",
    "\n",
    "# Seleccionamos el primer elemento de la tabla\n",
    "print(df)\n",
    "\n",
    "df.iloc[0,0] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677f77c7",
   "metadata": {},
   "source": [
    "Seleccionar una sola columna o una sola fila devuelve una Serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68463b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar la última columna \n",
    "print(type(df.iloc[:,-1]))\n",
    "df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6564baf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar la última fila \n",
    "print(type(df.iloc[-1,:]))\n",
    "df.iloc[-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364d32c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Al igual que el indexado de arrays bidimensionales en numpy, si indicamos solamente un índice se selecciona la fila entera\n",
    "df.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919017a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos seleccionar un rango de filas (también funciona como vimos simplemente con los corchetes: df[0:3])\n",
    "df.iloc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cbcba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar elementos de la segunda y la tercera fila y de la segunda y la tercera columna\n",
    "df.iloc[1:3,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd69168",
   "metadata": {},
   "source": [
    "#### 4. Ejemplos con máscaras (**indexado booleano**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca0cd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando el dataframe y quedando solo con las filas con temperatura mayor que 100\n",
    "df[df[\"Temperatura\"]>100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b90dd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando por temperatura mayor que 100 y quedando solamente con las dos últimas columnas\n",
    "df.loc[df[\"Temperatura\"]>100, ['Funcionalidad', 'Potencia']] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bd6003",
   "metadata": {},
   "source": [
    "Además de filtrado, podemos crear y añadir nuevas filas y columnas a raíz de las filas y las columnas existentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37af0d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadir una nueva fila con el índice 'f' que consiste en replicar los valores de la primera fila 'a'\n",
    "df.loc['f'] = df.loc['a']\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3d68ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una nueva columna para indicar la potencia en MW \n",
    "df['Potencia_MW'] = df['Potencia']/1000\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e6f6c3",
   "metadata": {},
   "source": [
    "### Métodos para los DataFrames \n",
    "* **.head()** muestra las primeras filas del DataFrame (por defecto las 5 primeras) y es muy útil para cuando tenemos muchas filas\n",
    "* **.mean()** muestra la media de las columnas\n",
    "* **.describe()**  muestra un resumen de todas las columnas, con cálculos **estadísticos básicos** (solo lo hace para las columnas numéricas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef11d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97168241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Media de una columna\n",
    "df['Potencia'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2348d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Media de todas las columnas (para la columna \"Funcionalidad\" convierte True a 1 y False a 0)\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654eda6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() # Sólo las columnas numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011c8123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos hacer visiualizaciones rápidas (por debajo se usa matplotlib)\n",
    "df['Potencia'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d476a400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# De la columna 'Potencia', podemos hacer un histograma\n",
    "df['Potencia'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96391542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para la columna 'Potencia' consultamos la frecuencia de los valores\n",
    "df['Potencia'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8cd975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para la columna 'Potencia' consultamos los valores únicos\n",
    "df['Potencia'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25868238",
   "metadata": {},
   "source": [
    "### Tratando los valores perdidos\n",
    "Pandas trata los valores **None** y **NaN** indistintamente para indicar valores perdidos. Para facilitar el tratamiento de estos valores existen métodos que nos permiten detectar, imputar o eliminar estos valores perdidos, estos métodos son:\n",
    "\n",
    "* **isnull():** genera una máscara booleana indicando los valores perdidos.\n",
    "\n",
    "* **notna()** y **notnull():** opuestos a isnull(), es decir, generan una máscara indicando los valores que no son perdidos.\n",
    "\n",
    "* **dropna():** retorna una versión filtrada de los datos sin valores perdidos.\n",
    "\n",
    "* **fillna():** retonar una versión de los datos con los valores perdidos imputados o rellenos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458b43ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificamos algunos elementos para introducir valores perdidos (cambiando su valor a NaN)\n",
    "df.loc['a', 'Potencia'] = df.loc['c', 'Potencia'] = np.nan\n",
    "df.loc['b', 'Temperatura'] = df.loc['f', 'Temperatura'] = np.nan\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9264ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8057ae08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d9c8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por defecto se quitan aquellas filas que contengan algún valor nulo\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24d123c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se puede indicar en el argumento 'axis' que se eliminen las columnas con valores perdidos en vez de filas\n",
    "df.dropna(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4393e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenar los valores perdidos \n",
    "df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a331e9b1",
   "metadata": {},
   "source": [
    "### Operando con valores perdidos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b437ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos creamos un numpy array con uno de sus valores igual a NaN\n",
    "valores = np.array([1, 2, 3, np.nan])\n",
    "print(valores)\n",
    "print(valores.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1114fc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos unos calculos sobre el array (cualquier operación que contenga un valor NaN devolverá NaN)\n",
    "print(valores.sum())\n",
    "print(valores.min())\n",
    "print(valores.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4409dd29",
   "metadata": {},
   "source": [
    "Numpy dispone de operaciones especiales que ignoran estos valores perdidos: **np.nansum()** , **np.nanmin()** , **np.nanmax()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc507260",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacemos uso de las funciones que ignoran los valores perdidos\n",
    "print(np.nansum(valores))\n",
    "print(np.nanmin(valores))\n",
    "print(np.nanmax(valores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8430d6b0",
   "metadata": {},
   "source": [
    "### Funciones en DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee1699d",
   "metadata": {},
   "source": [
    "Breve recordatorio sobre las **funciones lambda**:\n",
    "* A veces necesitamos tener funciones que son tan sencillas que no merece la pena ni siquiera que tengan nombre o estén declaradas. \n",
    "* Existe una sintaxis para hacer eso en Python en una sola línea.\n",
    "* Se utiliza la palabra clave lambda seguida de las variables, dos puntos y la expresión: `lamda variables: expresión`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61983672",
   "metadata": {},
   "source": [
    "**El método Apply():**\n",
    "Este método nos permite aplicar una función arbitraria a cada uno de los grupos. La función debería tomar un DataFrame y devolver un objeto tipo Pandas (DataFrame o Series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e18383",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8e43b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devuelve una serie con la suma de todos los elementos (axis=0 para las columnas)\n",
    "df.apply(np.sum, axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1a10bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# axis=1 para las filas\n",
    "df.apply(np.sum, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90834d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo de apply usando la función lambda, sumo 1 a todos los datos del DataFrame \n",
    "df.apply(lambda x: x + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf48e3b",
   "metadata": {},
   "source": [
    "### **`Ejercicio 4.3`**\n",
    "\n",
    "Conseguimos el Dataset de [Auto MPG](https://archive.ics.uci.edu/ml/datasets/auto+mpg) que contiene datos del consumo de combustible de diversos modelos de coches. \n",
    "\n",
    "**`4.3.1`** ¿Qué coche pesa más de 5000 kg?    \n",
    "**`4.3.2`** ¿Cuál es el número de cilindros más frecuente en los coches que son del año 76?  \n",
    "**`4.3.3`** Compara el consumo medio de los coches fabricados en el año 70 con los del año 79 y calcula la diferencia.    \n",
    "**`4.3.4`** Identifica las variables que contienen valores nulos (missing values) en caso que haya alguno.    \n",
    "**`4.3.5`** Consigue un DataFrame de aquellos registros que tengan algún valor nulo (NaN), filtrando el DataFrame original.  \n",
    "**`4.3.6`** Calcula la frecuencia del número de cilindros entre los registros del DataFrame anterior (la tabla con valores perdidos).  \n",
    "**`4.3.7`** Crea un DataFrame de los modelos con 6 o más cilindros, que pesén más de 4000 kg y consumen menos o igual que 10 galón por milla, filtrando el dataset original.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca194e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargar los datos desde la página de UCI\n",
    "\n",
    "path = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
    "\n",
    "mpg_data = pd.read_csv(path, delim_whitespace=True, header=None,\n",
    "            names = ['mpg', 'cilindros', 'desplazamiento','potencia',\n",
    "            'peso', 'aceleración', 'año', 'origen', 'nombre'],\n",
    "            na_values='?')\n",
    "\n",
    "# El DataFrame que se carga\n",
    "mpg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0ae58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solución\n",
    "# Ejercicio 4.3.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9743c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solución\n",
    "# Ejercicio 4.3.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbcc028",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solución\n",
    "# Ejercicio 4.3.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872932a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solución\n",
    "# Ejercicio 4.3.4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b4847a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solución\n",
    "# Ejercicio 4.3.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e7736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solución\n",
    "# Ejercicio 4.3.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a7e894",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solución\n",
    "# Ejercicio 4.3.7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c09eed",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2816e14",
   "metadata": {},
   "source": [
    "## Combinando Datasets: Concatenate, Merge y Join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc325c5",
   "metadata": {},
   "source": [
    "### Concatenación de datso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774a1e2a",
   "metadata": {},
   "source": [
    "**Concatenación simple:** \n",
    "* Pandas dispone de la función **pd.concat()**, que tiene una sintaxis muy similar a **np.concatenate**, pero contiene una serie de argumentos adicionales. \n",
    "* **pd.concat()** puede ser usada como una simple concatenación entre objetos de tipo Serie o tipo DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113edb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos creamos dos dataframes\n",
    "df1 = pd.DataFrame(np.array([[1, 2], [3, 4]]),\n",
    "                   columns=['x', 'y'], index = ['a','b'])\n",
    "\n",
    "df2 = pd.DataFrame(np.array([[1, 4], [4, 6]]),\n",
    "                   columns=['x', 'y'], index = ['c','d'])\n",
    "print(df1)\n",
    "print(\"\\n\",df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dec496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenamos (por defecto la concatenación se realiza por filas, si queremos que sea por columnas: axis = 1)\n",
    "print(pd.concat([df1,df2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1005e696",
   "metadata": {},
   "source": [
    "**Concatenación mediante joins:**\n",
    "* En los ejemplos que hemos visto anteriormente hemos realizado la concatenación de dataframes que compartian columnas. \n",
    "* En la práctica, los datos que vienen de fuentes diferentes podrían tener diferentes columnas, en estos casos la función **pd.concat()** ofrece distintas opciones. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967dd2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consideremos la concatenación de dos DataFrames, que comparten algunas columnas y otras no\n",
    "df3 = pd.DataFrame(np.array([[1, 2], [3, 4]]),\n",
    "                   columns=['x', 'y'], index = ['a','b'])\n",
    "\n",
    "df4 = pd.DataFrame(np.array([[1, 4], [4, 6]]),\n",
    "                   columns=['x', 'z'], index = ['c','d'])\n",
    "\n",
    "print(df3)\n",
    "print(\"\\n\",df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6c12a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df3, df4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba27da4c",
   "metadata": {},
   "source": [
    "* Por defecto los datos que no machean son rellenados por *NaN*. \n",
    "* Para cambiar esto, podemos especificar el parámetro **join**. \n",
    "* Por defecto, el **join** es una unión de las columnas de entrada (**join = outer**), pero podemos cambiar esto a una intersección de columnas (**join = inner**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142183d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos un join inner\n",
    "pd.concat([df3, df4], join = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886a6702",
   "metadata": {},
   "source": [
    "### Categorías de join\n",
    "* La función **pd.merge()** implementa varios tipos de joins: el **one-to-one**, **many-to-one** y **many-to-many**. \n",
    "* Los tres tipos de join son accesibles de forma idéntica a través de la función **pd.merge()**, el tipo de join realizado depende la forma de los datos de entrada. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd399376",
   "metadata": {},
   "source": [
    "* **One-to-one joins:**\n",
    "Se trata del tipo de join más simple, el cual en muchas ocasiones es muy similar a la concatenación por columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c50ff0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos dos dataframes, por ejemplo:\n",
    "df1 = pd.DataFrame({'empleado': ['Borja', 'Jose', 'Lola', 'Sofía'],\n",
    "'departamento': ['Contabilidad', 'IT', 'IT', 'RRHH']})\n",
    "df2 = pd.DataFrame({'empleado': ['Lola', 'Borja', 'Jose', 'Sofía'],\n",
    "'antigüedad': [2021, 2008, 2022, 2014]})\n",
    "\n",
    "print(df1)\n",
    "print(\"\\n\",df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6745ab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probamos la concatenación de los dos DtaFrames para compararlo con el merge\n",
    "pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64007aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos el merge entre los dos cojuntos de datos\n",
    "df3 = pd.merge(df1, df2)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a0edfc",
   "metadata": {},
   "source": [
    "La función **pd.merge()** es capaz de reconocer que ambos conjuntos de datos comparten la columna **employee**, y de forma automática realiza la unión por esta columna, es decir, usa dicha columna como clave. El resultado de la unión es un nuevo DataFrame que contiene la info de las dos entradas. Además la función **pd.merge()** no mantiene el índice, salvo que esta unión se haga por el índice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fd987a",
   "metadata": {},
   "source": [
    "* **Many-to-one joins:** Se tratan de joins en los cuales una de las dos columnas clave contiene entradas duplicadas. En este caso el DataFrame resultante mantendrá estos valores duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870a6db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaramos un nuevo DataFrame\n",
    "df4 = pd.DataFrame({'departamento': ['Contabilidad', 'IT', 'RRHH'],'supervisor': ['Celia', 'Gabriel', 'Sergio']})\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a351b151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos el merge de los dos últimos DataFrames\n",
    "pd.merge(df3, df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a515c1f",
   "metadata": {},
   "source": [
    "* **Many-to-many joins:**\n",
    "Si las dos columnas clave, contienen valores duplicados, entonces el resultado es un many-to-many merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70b3dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.DataFrame({'departamento': ['Contabilidad', 'Contabilidad','IT', 'IT', 'RRHH', 'RRHH'],\n",
    "                    'competencias': ['Matemáticas', 'Economía', 'programación', 'Cloud','Excel', 'Comunicación']})\n",
    "print(df1)\n",
    "print(\"\\n\",df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ddbce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos el merge\n",
    "pd.merge(df1,df5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32aba93",
   "metadata": {},
   "source": [
    "**Especificando la clave para el Merge:**\n",
    "* Parámetro **on**: podemos especificar de forma explícita el nombre de la columna que queremos que se utilice como clave. Este valor puede tomar el nombre de la columna o bien una lista de columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b40ed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1)\n",
    "print(\"\\n\",df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4640ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mergeamos los dos DataFrames indicando la columna clave\n",
    "pd.merge(df1, df2, on = 'empleado')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4067b541",
   "metadata": {},
   "source": [
    "**Especificando operaciones aritméticas en joins**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d9f4d3",
   "metadata": {},
   "source": [
    "* Por defecto la función **merge()** realiza lo que se conoce como inner join, es decir, se realiza la intersección entre ambos conjuntos de datos. \n",
    "* Podemos especificar el tipo mediante el parámetro **how**.\n",
    "* Los valores que puede tomar el argumento **how** son: **inner** (intersección datos), **outer** (unión datos), **left**, **right**. \n",
    "* Los valores **left_join** y **right_join** nos retornan las uniones respecto a los dataframes respectivos. Es decir, si hacemos un **left_join** mantendremos los valores de la tabla de la izquierda más la unión de estos valores con la tabla de la derecha.\n",
    "* Los valores perdidos son rellenados como NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0873f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Supongamos el siguiente conjunto de datos\n",
    "df6 = pd.DataFrame({'nombre': ['Pedro', 'Carlos', 'María'],'comida': ['carne', 'embutido', 'pescado']}, columns=['nombre', 'comida'])\n",
    "df7 = pd.DataFrame({'nombre': ['María', 'Javier'],'bebida': ['sidra', 'cerveza']},columns=['nombre', 'bebida'])\n",
    "print(df6)\n",
    "print(\"\\n\",df7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad61ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df6, df7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11104b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos el merge con outr (la unión)\n",
    "pd.merge(df6, df7, how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eaa6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos el merge con left_join\n",
    "pd.merge(df6, df7, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0d7244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos el merge con righ_join\n",
    "pd.merge(df6, df7, how = 'right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68fded6",
   "metadata": {},
   "source": [
    "## Groupby: Split, Apply, Combine\n",
    "Si bien las agregaciones simples pueden darle un significado a nuestros datos, en determinadas situaciones es posible que queramos realizar estas agregaciones a partir de una serie de índices o etiquetas: esto puede ser realizado mediane la operación **groupby**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d8c318",
   "metadata": {},
   "source": [
    "* El paso **split** implica dividir y agrupar un DataFrame, según el valor de la clave especificada.\n",
    "\n",
    "* El paso **apply** implica aplicar una función usualmente de agregación, transformación o filtrado a cada uno de los grupos individuales.\n",
    "\n",
    "* El paso **combine** finalmente unifica los resultados en un solo array o dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5360a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos un conjunto de datos tipo DataFrame (con los índices por defecto)\n",
    "df = pd.DataFrame({'key': ['A', 'B', 'C', 'B', 'A', 'B', 'C'],\n",
    "                   'data': range(7)}, columns=['key', 'data'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8846b9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc947ad2",
   "metadata": {},
   "source": [
    "* La potencia de la operación groupby es que permite al usuario ignorar como se realizan todas estas operaciones por detrás.\n",
    "* Podemos calcular el conjunto de operaciones split, apply y combine simplemente haciendo uso de la función **groupby** pasándole la clave por la cual deseamos realizar esto.\n",
    "* Podemos notar que no retorna un objeto de tipo DataFrame, sino que retorna un objeto de tipo **DataFrameGroupBy**. Este objeto, se trata de un objeto que está preparado para atacar a los grupos , pero no realiza un cálculo real hasta que no se realice algún tipo de agregación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a78420",
   "metadata": {},
   "source": [
    "Vamos a intentar sumar todos los datos de A, todos los de B y todos los de C. Sin hacer uso de **groupby()**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e34a98",
   "metadata": {},
   "source": [
    "1. **Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffde7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar los registros de A\n",
    "df_A = df[df['key']=='A']\n",
    "df_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124a12c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar los registros de B\n",
    "df_B = df[df['key']=='B']\n",
    "df_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc30071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar los registros de C\n",
    "df_C = df[df['key']=='C']\n",
    "df_C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b5decd",
   "metadata": {},
   "source": [
    "2. **Apply**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbda5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumamos los de A \n",
    "sum_A = df_A['data'].sum()\n",
    "sum_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5948bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumamos los de B \n",
    "sum_B = df_B['data'].sum()\n",
    "sum_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bd4010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumamos los de C\n",
    "sum_C = df_C['data'].sum()\n",
    "sum_C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aad50b0",
   "metadata": {},
   "source": [
    "3. **Combine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59bf606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir el DataFrame con los resultados obtenidos de las sumas por separado\n",
    "d = {'key': ['A', 'B', 'C'],\n",
    "    'suma': [sum_A, sum_B, sum_C]}\n",
    "\n",
    "df_sumas = pd.DataFrame(d)\n",
    "df_sumas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35541aa",
   "metadata": {},
   "source": [
    "Vemos que esta forma de sumar los datos de A, B y C es bastante tediosa.\n",
    "Sin embargo, podemos realizar la misma operación con una sola línea de código usando la función **groupy()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0b79a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos la agregación de sumatorio\n",
    "df.groupby('key').sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55407f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos la agregación de mínimo \n",
    "df.groupby('key').min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80de9dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos la agregación de conteo para cada grupo\n",
    "df.groupby('key').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f204367a",
   "metadata": {},
   "source": [
    "* El objeto de tipo **GroupBy** se trata de un objeto muy **flexible** que nos permite realizar una serie de operaciones bastante complejas de una forma más sencilla.\n",
    "\n",
    "* Los objetos de tipo GroupBy al igual que los objetos de tipo DataFrame permiten la indexación por columnas.\n",
    "* Dado un objeto de tipo **Groupby** podemos hacer uso de los distintos métodos vistos para cada uno de los grupos por ejemplo podemos aplicar el método **describe()**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df91dc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b35b82",
   "metadata": {},
   "source": [
    "**Agregación:**\n",
    "Hasta ahora estamos familiarizados con las agregaciones **sum()**, **mean()** etc para la función GroupBy. La función **aggregate()** (o **agg()**) nos permite una mayor flexibilidad, esta función puede tomar una lista de agregaciones y computar todas de una sola vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d053b3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasamoa la función min mesiante aggregate\n",
    "df.groupby('key').agg(min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c7ff4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos de golpe una lista de funciones con aggregate\n",
    "df.groupby('key').aggregate(['min', np.median, max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce95c5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir una función que saca el número total de bytes consumido para cada grupo y aplicarlo mediante aggregate()\n",
    "num_bytes_total = lambda x: x.nbytes\n",
    "df.groupby('key').aggregate(num_bytes_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cd40ff",
   "metadata": {},
   "source": [
    "**Transformación:**\n",
    "Mientras que la agregación retorna una versión reducida de los datos, **.transform()** retorna una versión completa de los datos transformados. Por lo tanto la salida tras aplicar una transformación es de igual tamaño que los datos de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491a15bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9351be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key').aggregate(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abde713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key').transform(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f42668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['key']).transform(max) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b79f8dc",
   "metadata": {},
   "source": [
    "El método **transform()** sirve sobre todo a la hora de **crear nuevas variables (columnas)** con la salida de groupby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f8b56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadimos una nueva columna que indique el valor máximo de todos los valores por grupo\n",
    "df[\"max_grupo\"] = df.groupby(['key']).transform(max) \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e865a0a5",
   "metadata": {},
   "source": [
    "### **`Ejercicio 4.4`**\n",
    "\n",
    "**`4.4.1`** Ejecutando las siguientes celdas se obtienen dos DataFrames que contienen varias lecturas de datos metorológicos de diferentes ciudades en difrentes momentos del año. Concatena las dos tablas de forma básica.     \n",
    "**`4.4.2`** Concatena las dos tablas solamente con la información que tengan en común.  \n",
    "**`4.4.3`** A continuación viene otra celda para generar dos tablas que corresponden a número de aportaciones de cada desarrollador de un equipo de análisi de datos en diferentes versiones liberadas de una aplicación corporativa (Released versions). Concatena de forma básica los dos DataFrames y calcula el número de filas de la tabla concatenada.  \n",
    "**`4.4.4`** Realiza un merge con la unión de los dos DataFrames y calcula el número de filas de la tabla resultante.  \n",
    "**`4.4.5`** Realiza un merge con la intersección. de los dos DataFrames y calcula el número de filas de la tabla resultante.  \n",
    "**`4.4.6`** Volviendo al dataset de \"Auto-MPG\" usado en el ejercicio 4.3, genera de nuevo el DataFrame y después saca las medias de cada variable por año.  \n",
    "**`4.4.7`** Dibuja la evolución del valor medio de cada variable por año.  \n",
    "**`4.4.8`** Dibuja solamente la gráfica del peso medio de los coches a lo largo de los años.  \n",
    "\n",
    "    \n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8382f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ejercicio 4.4.1\n",
    "\n",
    "lectura1 = {'ciudad':'Valencia', 'temperatura':21, 'o2':1}\n",
    "lectura2 = {'ciudad':'Barcelona', 'temperatura':18, 'o2':0.85}\n",
    "lectura3 = {'ciudad':'Valencia', 'temperatura':27, 'o2':0.95}\n",
    "\n",
    "df_met1 = pd.DataFrame([lectura1, lectura2, lectura3], index=list('abc'))\n",
    "df_met1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c7c9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ejercicio 4.4.1\n",
    "\n",
    "lectura4 = {'ciudad':'Madrid', 'temperatura':31, 'humedad':40, 'co2':14}\n",
    "lectura5 = {'ciudad':'Sevilla', 'temperatura':33, 'humedad':80, 'co2':6}\n",
    "lectura6 = {'ciudad':'Valencia', 'temperatura':29, 'humedad':90, 'co2':10}\n",
    "\n",
    "df_met2 = pd.DataFrame([lectura4, lectura5, lectura6], index=list('def'))\n",
    "df_met2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solución\n",
    "# Ejercicio 4.4.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d1ba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solución\n",
    "# Ejercicio 4.4.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4d6d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ejercicio 4.4.3\n",
    "\n",
    "analistas1 = pd.DataFrame([[\"Sara\",4,3,8],[\"Manuel\",2,7,3],[\"Pablo\",2,6,4],[\"Antonio\",1,9,6]], columns=[\"Name\",\"B\",\"C\", \"D\"])\n",
    "\n",
    "analistas2 = pd.DataFrame([[\"Claudia\",6,3],[\"Luis\",10,7],[\"Sara\",7,11],[\"Pablo\",12,14]], columns=[\"Name\",\"F\",\"G\"])\n",
    "\n",
    "display(analistas1)\n",
    "display(analistas2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937d0676",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solución\n",
    "# Ejercicio 4.4.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2529705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solución\n",
    "# Ejercicio 4.4.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c92519",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solución\n",
    "# Ejercicio 4.4.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7d1c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ejercicio 4.4.6\n",
    "\n",
    "path = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
    "\n",
    "mpg_data = pd.read_csv(path, delim_whitespace=True, header=None,\n",
    "            names = ['mpg', 'cilindros', 'desplazamiento','potencia',\n",
    "            'peso', 'aceleración', 'año', 'origen', 'nombre'],\n",
    "            na_values='?')\n",
    "\n",
    "# El DataFrame que se carga\n",
    "mpg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bbfb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solución\n",
    "# Ejercicio 4.4.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ce0119",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solución\n",
    "# Ejercicio 4.4.7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b070ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solución\n",
    "# Ejercicio 4.4.8\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
